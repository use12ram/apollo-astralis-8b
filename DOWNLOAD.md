# üì¶ Model Files

The model weights and GGUF files are hosted on HuggingFace and Ollama due to GitHub's file size limitations.

## Download Options

### ü§ó HuggingFace (Full Package)
**Recommended for fine-tuning and research**

- **LoRA Adapters**: `adapter_model.safetensors` (167MB)
- **GGUF Quantized**: `apollo_astralis_8b.gguf` (4.7GB)
- **All configs and tokenizer files included**

```bash
# Clone with Git LFS
git clone https://huggingface.co/vanta-research/apollo-astralis-8b

# Or download specific files
wget https://huggingface.co/vanta-research/apollo-astralis-8b/resolve/main/adapter_model.safetensors
wget https://huggingface.co/vanta-research/apollo-astralis-8b/resolve/main/apollo_astralis_8b.gguf
```

### ü¶ô Ollama (Instant Use)
**Recommended for local inference**

```bash
# One command to download and run
ollama run vanta-research/apollo-astralis-8b
```

## What's in This Repo?

This GitHub repository contains:
- ‚úÖ Complete documentation (README, MODEL_CARD, USAGE_GUIDE, MERGE_GUIDE)
- ‚úÖ Configuration files (adapter_config.json, config.json, tokenizer configs)
- ‚úÖ Tokenizer files (vocab.json, merges.txt, tokenizer.json)
- ‚ùå Model weights (too large for GitHub - get from HuggingFace or Ollama)

## Quick Links

- ü§ó **HuggingFace**: https://huggingface.co/vanta-research/apollo-astralis-8b
- ü¶ô **Ollama**: https://ollama.com/vanta-research/apollo-astralis-8b
- üìñ **Full Documentation**: See [README.md](./README.md)
